{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Recognition with Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2, random\n",
    "import pywt, pywt.data\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join, dirname\n",
    "from tqdm import tqdm\n",
    "from yuface import detect\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FR:\n",
    "    def __init__(self):\n",
    "        self.DIR = 'C:/Programming/Python/Face_Recognition'\n",
    "        self.RAWIMAGEDIR = 'C:/Programming/Python/Face_Recognition'\n",
    "        self.imgFileList = [] # Full path of the image filenames\n",
    "        self.croppedfaceImgList = [] # Cropped face images\n",
    "        self.labelList = [] # Image labels\n",
    "        self.trainImages = []\n",
    "        return\n",
    "    \n",
    "    def getDirList(self) -> None:\n",
    "        datafile = [f for f in listdir(self.RAWIMAGEDIR) if isdir(join(self.RAWIMAGEDIR, f))]\n",
    "        return datafile\n",
    "    \n",
    "    def getImageFiles(self) -> None:\n",
    "        myDirs = self.getDirList()\n",
    "        for dir in tqdm(myDirs):\n",
    "            # datafile1 = [self.RAWIMAGEDIR + '/' + dir + '/' + f for f in listdir(self.RAWIMAGEDIR + '/' + dir) if isfile(join(self.RAWIMAGEDIR + '/' + dir, f))]\n",
    "            for f in listdir(self.RAWIMAGEDIR + '/' + dir):\n",
    "                if isfile(join(self.RAWIMAGEDIR + '/' + dir, f)):\n",
    "                    self.imgFileList.append(self.RAWIMAGEDIR + '/' + dir + '/' + f)\n",
    "                    image = cv2.imread(self.imgFileList[-1])\n",
    "                    image = cv2.resize(image, (256, 256))\n",
    "                    self.trainImages.append(image)\n",
    "                    self.labelList.append(dir)\n",
    "        return\n",
    "    \n",
    "    def getCroppedface(self, img: np.array) -> np.array:\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, bboxes, _ = detect(img, conf=0.5)\n",
    "        if bboxes.size != 0:\n",
    "            bbox = bboxes[0]\n",
    "            img1 = img[bbox[1]:(bbox[1]+bbox[3]), bbox[0]:(bbox[0]+bbox[2])]\n",
    "            return img1\n",
    "        else:\n",
    "            return np.array([])\n",
    "    \n",
    "    # def waveletTransformation(self, img: np.array) -> np.array:\n",
    "    #     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #     coeffs2 = pywt.dwt2(img, \"bior1.3\")\n",
    "    #     return coeffs2\n",
    "    \n",
    "    def getCroppedfaceImageList(self) -> None:\n",
    "        self.getImageFiles()\n",
    "        for imgfile in tqdm(self.imgFileList):\n",
    "            img = cv2.imread(imgfile, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            img = self.getCroppedface(img)\n",
    "            # img = cv2.resize(img, (256, 256))\n",
    "            if (img is not None):\n",
    "                if img.size > 5000:\n",
    "                    img = cv2.resize(img, (256, 256))\n",
    "                    self.croppedfaceImgList.append(img)\n",
    "                    self.trainImages.append(img)\n",
    "                    self.labelList.append(dirname(imgfile).split('/')[-1])\n",
    "                    # Wavelet Transformation\n",
    "                    # try:\n",
    "                    #     LL, (LH, HL, HH) = self.waveletTransformation(img)\n",
    "                    #     for pwImg in [LL, LH, HL, HH]:\n",
    "                    #         pwImg = cv2.resize(pwImg, (256, 256))\n",
    "                    #         pwImg = cv2.merge((pwImg, pwImg, pwImg)).astype(np.uint)\n",
    "                    #         self.trainImages.append(pwImg)\n",
    "                    #         self.labelList.append(dirname(imgfile).split('/')[-1])\n",
    "                    # except:\n",
    "                    #     continue\n",
    "        return \n",
    "    \n",
    "    def getCleanedData(self) -> None:\n",
    "        self.getCroppedfaceImageList()\n",
    "        trainImages = 'C:/Programming/Python/Face_Recognition/Train_Data/trainImages.npy'\n",
    "        trainLabels = 'C:/Programming/Python/Face_Recognition/Train_Data/trainLabels.npy'\n",
    "        np.save(trainImages, np.array(self.trainImages))\n",
    "        np.save(trainLabels, np.array(self.labelList))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fr = FR()\n",
    "    if not isfile ('C:/Programming/Python/Face_Recognition/Train_Data/trainImages.npy') & isfile('C:/Programming/Python/Face_Recognition/Train_Data/trainLabels.npy'):\n",
    "        fr.getCleanedData()\n",
    "    X = np.load('C:/Programming/Python/Face_Recognition/Train_Data/trainImages.npy', allow_pickle=True)\n",
    "    y = np.load('C:/Programming/Python/Face_Recognition/Train_Data/trainLabels.npy', allow_pickle=True)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random check of images\n",
    "for i in range(2):\n",
    "    val = random.randint(0, y.shape[0])\n",
    "    img = cv2.cvtColor(X[val], cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(y[val])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Pre-processing data . . .')\n",
    "X = applications.xception.preprocess_input(X.astype(\"float64\"))\n",
    "#  Label encode the categorical output\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if data is normalized to between -1 to +1\n",
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random image check\n",
    "num = random.randint(0, y.shape[0])\n",
    "img = ((X[num] + 1) / 2)\n",
    "b, g, r = cv2.split(img)\n",
    "img = cv2.merge([r, g, b])\n",
    "plt.imshow(img)\n",
    "plt.title(le.inverse_transform([y[num]])[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isfile(\"C:/Programming/Python/Face_Recognition/Models/xception_transfer_learning_model.keras\"):\n",
    "    # First Train the top layers (which we have added)\n",
    "    num_classes = len(list(set(y)))\n",
    "    pre_trained_layer = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = (X.shape[1], X.shape[2], X.shape[3]))\n",
    "    x = pre_trained_layer.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=pre_trained_layer.input, outputs=predictions)\n",
    "    for layer in pre_trained_layer.layers:\n",
    "        layer.trainable = False\n",
    "    # 'categorical_crossentropy' works on one-hot encoded target, while 'sparse_categorical_crossentropy' works on integer target. Here we are using Label Encoder,\n",
    "    #  hence the 'sparse_categorical_crossentropy'\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print (model.summary(show_trainable=True))\n",
    "    model.fit(X, y, validation_split=0.25, shuffle=True, epochs=25, batch_size=32, verbose=1)\n",
    "\n",
    "    # Now choose the layer from the pre-trained network which we want to un-freeze in addition to the top layers and re-train.\n",
    "    for layer in model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[100:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print (model.summary(show_trainable=True))\n",
    "    model.fit(X, y, validation_split=0.15, shuffle=True, epochs=25, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Instead of unfreezing the entire model, we unfreezed the top 100 layers in the above code.\n",
    "    # # Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "    # # since we passed `training=False` when calling it. This means that\n",
    "    # # the batchnorm layers will not update their batch statistics.\n",
    "    # # This prevents the batchnorm layers from undoing all the training\n",
    "    # # we've done so far. Ref: https://keras.io/guides/transfer_learning/\n",
    "    # for layer in pre_trained_layer.layers:\n",
    "    #         layer.trainable = True\n",
    "    # model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-5), metrics=['accuracy'])\n",
    "    # print (model.summary(show_trainable='True'))\n",
    "    # model.fit(X, y, validation_split=0.15, shuffle=True, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    model.save('C:/Programming/Python/Face_Recognition/Models/xception_transfer_learning_model.keras')\n",
    "else:\n",
    "    model = load_model('C:/Programming/Python/Face_Recognition/Models/xception_transfer_learning_model.keras')\n",
    "    print (model.summary(show_trainable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(X, y, verbose=1)\n",
    "print(\"\\n%s: %.2f%%\" % ('Model ' + str.title(model.metrics_names[1]), score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "TEST_DIR = 'C:/Programming/Python/Face_Recognition/Test_Data/'\n",
    "Total_Count = 0\n",
    "Pass_Count = 0\n",
    "for f in listdir(TEST_DIR):\n",
    "    if isfile(join(TEST_DIR, f)):\n",
    "        label = f.split('.')[1]\n",
    "        img = cv2.imread(join(TEST_DIR, f), 1)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        cropped = fr.getCroppedface(img)\n",
    "        cropped = cv2.resize(cropped, (256, 256))\n",
    "        # plt.imshow(cropped)\n",
    "        # plt.title(f'{label}')\n",
    "        # plt.show()\n",
    "        # Check if decision can be made with cropped image for better accuracy\n",
    "        X = applications.xception.preprocess_input(cropped.astype(\"float64\"))\n",
    "        pred = model.predict(np.expand_dims(X, axis=0), verbose=0).max()\n",
    "        if pred > 0.9: # Image identified\n",
    "            pred = le.inverse_transform([np.argmax(model.predict(np.expand_dims(X, axis=0), verbose=0))])[0]\n",
    "            b, g, r = cv2.split(img)\n",
    "            img = cv2.merge([r, g, b])\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{label}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            confidence = round(model.predict(np.expand_dims(X, axis=0), verbose=0).max() * 100, 2)\n",
    "            print (f'Original: {label} - Predicted: {pred} ({confidence}%)')\n",
    "            Total_Count += 1\n",
    "            if label == pred:\n",
    "                Pass_Count += 1\n",
    "        else:\n",
    "            # Check if decision can be made with original image\n",
    "            X = applications.xception.preprocess_input(img.astype(\"float64\"))\n",
    "            pred = model.predict(np.expand_dims(X, axis=0), verbose=0).max()\n",
    "            if pred > 0.7: # Image identified\n",
    "                pred = le.inverse_transform([np.argmax(model.predict(np.expand_dims(X, axis=0), verbose=0))])[0]\n",
    "                b, g, r = cv2.split(img)\n",
    "                img = cv2.merge([r, g, b])\n",
    "                plt.imshow(img)\n",
    "                plt.title(f'{label}')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                confidence = round(model.predict(np.expand_dims(X, axis=0), verbose=0).max() * 100, 2)\n",
    "                print (f'Original: {label} - Predicted: {pred} ({confidence}%)')\n",
    "                Total_Count += 1\n",
    "                if label == pred:\n",
    "                    Pass_Count += 1\n",
    "            else:\n",
    "                b, g, r = cv2.split(img)\n",
    "                img = cv2.merge([r, g, b])\n",
    "                plt.imshow(img)\n",
    "                plt.title(f'{label}')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                pred1 = model.predict(np.expand_dims(X, axis=0), verbose=0)[0]\n",
    "                # Incase of indecision, get the best two predictions\n",
    "                pred = np.argpartition(pred1, -2)[-2:]\n",
    "                print (f'Original: {label} - Predicted: {le.inverse_transform([pred[1]])[0]} ({round(pred1[pred[1]]*100, 2)}%) or {le.inverse_transform([pred[0]])[0]} ({round(pred1[pred[0]]*100, 2)}%)')\n",
    "                Total_Count += 1\n",
    "print (f'Accuracy: Out of a total of {Total_Count} images, {Total_Count - Pass_Count} were misclassified.\\n%Pass: {round((Pass_Count / Total_Count) * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
